{
  "config": {
    "gate_type": "rule",
    "dataset": "synthetic",
    "metrics": [
      "auroc",
      "accuracy"
    ],
    "output_dir": "eval_results",
    "num_trials": 1,
    "train_split": 0.7,
    "val_split": 0.15,
    "test_split": 0.15,
    "seed": 42,
    "device": "cpu"
  },
  "overall_metrics": {
    "auroc": 0.9832177220854778,
    "accuracy": 0.9266666666666666,
    "abstain_rate": 0.06,
    "avg_confidence": 0.30227023428464805,
    "prediction_variance": 0.0872832893610906
  },
  "per_regime_metrics": {
    "aligned": {
      "auroc": 0.5,
      "accuracy": 0.9541284403669725,
      "abstain_rate": 0.0
    },
    "contradictory": {
      "auroc": 0.5,
      "accuracy": 0.8536585365853658,
      "abstain_rate": 0.21951219512195122
    }
  },
  "calibration_metrics": {
    "brier_score": 0.06575827099216085
  },
  "gate_confusion": {
    "expert_usage": {
      "AlignedExpert": 0.84,
      "AntiBExpert": 0.11333333333333333,
      "AntiAExpert": 0.04666666666666667
    },
    "regime_routing": {
      "aligned": {
        "AlignedExpert": 0.8348623853211009,
        "AntiBExpert": 0.11009174311926606,
        "AntiAExpert": 0.05504587155963303
      },
      "contradictory": {
        "AntiAExpert": 0.024390243902439025,
        "AlignedExpert": 0.8536585365853658,
        "AntiBExpert": 0.12195121951219512
      }
    },
    "routing_accuracy": {
      "AlignedExpert": 0.8669031958672262,
      "AntiBExpert": 0.5280258077032426,
      "AntiAExpert": 0.5328198543616703
    }
  },
  "coverage_analysis": {
    "risk_at_80": 0.1776219652655224,
    "actual_coverage_80": 0.8,
    "risk_at_90": 0.17324556037783623,
    "actual_coverage_90": 0.9,
    "risk_at_95": 0.17986817293288843,
    "actual_coverage_95": 0.9466666666666667
  },
  "expert_performance": {
    "AlignedExpert": {
      "n_predictions": 126,
      "mse": 0.035446548481623076,
      "mae": 0.13309680413277375,
      "abstain_rate": 0.07142857142857142,
      "predictions": 795,
      "avg_confidence": 0.7053545105382332,
      "confidence_std": 0.12693597472810525
    },
    "AntiBExpert": {
      "n_predictions": 17,
      "mse": 0.22734223729871705,
      "mae": 0.4719741922967574,
      "abstain_rate": 0.0,
      "predictions": 114,
      "avg_confidence": 0.6310848733463241,
      "confidence_std": 0.22075311025858066
    },
    "AntiAExpert": {
      "n_predictions": 7,
      "mse": 0.21895107229449007,
      "mae": 0.46718014563832966,
      "abstain_rate": 0.0,
      "predictions": 91,
      "avg_confidence": 0.6718753765188714,
      "confidence_std": 0.2193500469146688
    }
  },
  "predictions": [
    {
      "prediction": 0.980322003364563,
      "confidence": 0.07150021836037186,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0010094642639160156,
        "delta": 0.1859721690416336,
        "magnitude_ratio": 0.016794830560684204
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 142
      }
    },
    {
      "prediction": 0.9534741640090942,
      "confidence": 0.3562537894619209,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0011990666389465332,
        "delta": 0.23507025837898254,
        "magnitude_ratio": 0.021573713049292564
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 684
      }
    },
    {
      "prediction": 0.9076213240623474,
      "confidence": 0.19145250434945663,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.007190883159637451,
        "delta": 0.2903745174407959,
        "magnitude_ratio": 0.015057438984513283
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 293
      }
    },
    {
      "prediction": 0.9505166411399841,
      "confidence": 0.3537469718347774,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002941429615020752,
        "delta": 0.24677060544490814,
        "magnitude_ratio": 0.01771419681608677
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 976
      }
    },
    {
      "prediction": 0.9873709082603455,
      "confidence": 0.3291641011751389,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0028296709060668945,
        "delta": 0.3226896822452545,
        "magnitude_ratio": 0.020827261731028557
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 418
      }
    },
    {
      "prediction": 0.6701087355613708,
      "confidence": 0.36110271149059586,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003506898880004883,
        "delta": 0.25663644075393677,
        "magnitude_ratio": 0.00011199712753295898
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 736
      }
    },
    {
      "prediction": 0.41433659195899963,
      "confidence": 0.5885653202488115,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9927818775177002,
        "delta": 5.49208402633667,
        "magnitude_ratio": 0.025180082768201828
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 633
      }
    },
    {
      "prediction": 0.19162550568580627,
      "confidence": 0.7576011081258089,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.989488124847412,
        "delta": 4.264917373657227,
        "magnitude_ratio": 0.009710840880870819
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 535
      }
    },
    {
      "prediction": 0.854225754737854,
      "confidence": 0.038786967924461735,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006896018981933594,
        "delta": 0.3183651268482208,
        "magnitude_ratio": 0.022409025579690933
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 381
      }
    },
    {
      "prediction": 0.909251868724823,
      "confidence": 0.27648115014805047,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0035317540168762207,
        "delta": 0.35089343786239624,
        "magnitude_ratio": 0.03903478756546974
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 923
      }
    },
    {
      "prediction": 0.021404331550002098,
      "confidence": 0.6631033364700093,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9904258251190186,
        "delta": 3.816805124282837,
        "magnitude_ratio": 0.01549829076975584
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 896
      }
    },
    {
      "prediction": 0.9457577466964722,
      "confidence": 0.28187499052472836,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0040871500968933105,
        "delta": 0.32806676626205444,
        "magnitude_ratio": 0.0067136469297111034
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 252
      }
    },
    {
      "prediction": 0.9789948463439941,
      "confidence": 0.2093411538812032,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002345860004425049,
        "delta": 0.23428790271282196,
        "magnitude_ratio": 0.01716594211757183
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 695
      }
    },
    {
      "prediction": 0.8893165588378906,
      "confidence": -0.01781722933212532,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005245327949523926,
        "delta": 0.2281026393175125,
        "magnitude_ratio": 0.002590531250461936
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 247
      }
    },
    {
      "prediction": 0.8708571791648865,
      "confidence": 0.019628552434586312,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.015549719333648682,
        "delta": 0.3073154389858246,
        "magnitude_ratio": 0.004848144017159939
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 798
      }
    },
    {
      "prediction": 0.9768534898757935,
      "confidence": 0.2368932621576099,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003821074962615967,
        "delta": 0.2978987991809845,
        "magnitude_ratio": 0.004012324847280979
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 632
      }
    },
    {
      "prediction": 0.9611024260520935,
      "confidence": 0.3062653217916413,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0027810335159301758,
        "delta": 0.3086162209510803,
        "magnitude_ratio": 0.007792434189468622
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 490
      }
    },
    {
      "prediction": 0.936285674571991,
      "confidence": 0.12870758472587113,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0037401914596557617,
        "delta": 0.26155146956443787,
        "magnitude_ratio": 0.0061431946232914925
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 356
      }
    },
    {
      "prediction": 0.6007574200630188,
      "confidence": 0.8901316688432725,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9982142448425293,
        "delta": 7.538774013519287,
        "magnitude_ratio": 0.0296267569065094
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 596
      }
    },
    {
      "prediction": -0.05387283116579056,
      "confidence": 0.7418691475069162,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9982054233551025,
        "delta": 6.432333469390869,
        "magnitude_ratio": 0.03020636923611164
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 793
      }
    },
    {
      "prediction": 0.9377236366271973,
      "confidence": 0.23775226613398723,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005986571311950684,
        "delta": 0.2921411097049713,
        "magnitude_ratio": 0.003476426936686039
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 29
      }
    },
    {
      "prediction": 0.5258641242980957,
      "confidence": -0.03428827535192259,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006275475025177002,
        "delta": 0.2521876096725464,
        "magnitude_ratio": 0.006052121985703707
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 434
      }
    },
    {
      "prediction": 0.6338542103767395,
      "confidence": 0.30446323572880707,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.00449293851852417,
        "delta": 0.2978871166706085,
        "magnitude_ratio": 0.006828261539340019
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 167
      }
    },
    {
      "prediction": 0.4985560476779938,
      "confidence": 0.7982601248727695,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.997847557067871,
        "delta": 8.005280494689941,
        "magnitude_ratio": 0.0021983350161463022
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 887
      }
    },
    {
      "prediction": 0.9670268893241882,
      "confidence": 0.32638067440749735,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.00396728515625,
        "delta": 0.33326229453086853,
        "magnitude_ratio": 0.01633218675851822
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 608
      }
    },
    {
      "prediction": 0.3661729097366333,
      "confidence": 0.8024594037855796,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9963622093200684,
        "delta": 6.5511088371276855,
        "magnitude_ratio": 0.016239764168858528
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 733
      }
    },
    {
      "prediction": 0.9756484627723694,
      "confidence": 0.21633513283381464,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0017510652542114258,
        "delta": 0.20356540381908417,
        "magnitude_ratio": 0.0065369270741939545
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 43
      }
    },
    {
      "prediction": 0.5321429371833801,
      "confidence": 0.6358637803524371,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.996403694152832,
        "delta": 5.30735445022583,
        "magnitude_ratio": 0.03686806559562683
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 270
      }
    },
    {
      "prediction": 0.9126150012016296,
      "confidence": 0.23292471373808202,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0035858154296875,
        "delta": 0.23980489373207092,
        "magnitude_ratio": 0.01649361290037632
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 610
      }
    },
    {
      "prediction": 0.9659749269485474,
      "confidence": 0.2601342571342595,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004590868949890137,
        "delta": 0.25038042664527893,
        "magnitude_ratio": 0.01057734340429306
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 245
      }
    },
    {
      "prediction": 0.2420109659433365,
      "confidence": 0.6717478603917405,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.988932490348816,
        "delta": 3.8221981525421143,
        "magnitude_ratio": 0.03396664187312126
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 203
      }
    },
    {
      "prediction": 0.7452086210250854,
      "confidence": -0.2088338998878867,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.02469193935394287,
        "delta": 0.38589587807655334,
        "magnitude_ratio": 0.0006173848523758352
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 125
      }
    },
    {
      "prediction": 0.18080773949623108,
      "confidence": 0.8862677352613874,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.998218297958374,
        "delta": 5.8549981117248535,
        "magnitude_ratio": 0.025935018435120583
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 977
      }
    },
    {
      "prediction": 0.9730015993118286,
      "confidence": 0.35168453733817034,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002592921257019043,
        "delta": 0.2567892074584961,
        "magnitude_ratio": 0.0067182364873588085
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 90
      }
    },
    {
      "prediction": 0.9598215818405151,
      "confidence": 0.265726716409883,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0025594234466552734,
        "delta": 0.2777600586414337,
        "magnitude_ratio": 0.019820597022771835
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 72
      }
    },
    {
      "prediction": 0.9576877951622009,
      "confidence": 0.33438536339023933,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.00730586051940918,
        "delta": 0.4036494195461273,
        "magnitude_ratio": 0.010087982751429081
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 660
      }
    },
    {
      "prediction": 0.9870201945304871,
      "confidence": 0.2821275178963652,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003338932991027832,
        "delta": 0.31037643551826477,
        "magnitude_ratio": 0.003923872951418161
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 969
      }
    },
    {
      "prediction": 0.1883353739976883,
      "confidence": 0.7696174748392153,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9912558794021606,
        "delta": 5.62824010848999,
        "magnitude_ratio": 0.02603997103869915
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 547
      }
    },
    {
      "prediction": 0.7807639837265015,
      "confidence": 0.18181961624357454,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0033301711082458496,
        "delta": 0.2550084590911865,
        "magnitude_ratio": 0.00762829277664423
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 960
      }
    },
    {
      "prediction": 0.5621644258499146,
      "confidence": 0.7488733736834678,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9954452514648438,
        "delta": 4.12484884262085,
        "magnitude_ratio": 0.005362340249121189
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 21
      }
    },
    {
      "prediction": 0.5108430981636047,
      "confidence": 0.0038629356892877637,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0029758214950561523,
        "delta": 0.2287648320198059,
        "magnitude_ratio": 0.025099845603108406
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 362
      }
    },
    {
      "prediction": 0.4604918658733368,
      "confidence": 0.7390070209687897,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9984214305877686,
        "delta": 6.896413803100586,
        "magnitude_ratio": 0.03157179802656174
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 176
      }
    },
    {
      "prediction": 0.930381715297699,
      "confidence": -0.0024979319132555264,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0022489428520202637,
        "delta": 0.19849126040935516,
        "magnitude_ratio": 0.001994488062337041
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 878
      }
    },
    {
      "prediction": 0.5250918865203857,
      "confidence": -0.008242665468801189,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.008089125156402588,
        "delta": 0.3076542615890503,
        "magnitude_ratio": 0.020970070734620094
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 20
      }
    },
    {
      "prediction": 0.7854850888252258,
      "confidence": 0.0032065249445842833,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0030410289764404297,
        "delta": 0.19727174937725067,
        "magnitude_ratio": 0.011258662678301334
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 379
      }
    },
    {
      "prediction": 0.8698190450668335,
      "confidence": -0.10374440557720606,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004523754119873047,
        "delta": 0.27156323194503784,
        "magnitude_ratio": 0.05115111917257309
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 961
      }
    },
    {
      "prediction": 0.24794436991214752,
      "confidence": 0.41858160078659273,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9873698949813843,
        "delta": 3.0501832962036133,
        "magnitude_ratio": 0.009682114236056805
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 784
      }
    },
    {
      "prediction": 0.44452965259552,
      "confidence": 0.8149418674301997,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9936078786849976,
        "delta": 5.591443061828613,
        "magnitude_ratio": 0.009022885002195835
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 719
      }
    },
    {
      "prediction": 0.9523963332176208,
      "confidence": 0.044547556501823765,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.009496450424194336,
        "delta": 0.3653484880924225,
        "magnitude_ratio": 0.00019305944442749023
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 691
      }
    },
    {
      "prediction": 0.9676125645637512,
      "confidence": 0.6009206445666527,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004461944103240967,
        "delta": 0.39884644746780396,
        "magnitude_ratio": 0.04046696797013283
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 720
      }
    },
    {
      "prediction": 0.9247536659240723,
      "confidence": 0.040297029375985526,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004138588905334473,
        "delta": 0.30262961983680725,
        "magnitude_ratio": 0.05116711184382439
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 599
      }
    },
    {
      "prediction": 0.9631933569908142,
      "confidence": 0.01679577901358351,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.00164031982421875,
        "delta": 0.18186509609222412,
        "magnitude_ratio": 0.0024085594341158867
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 393
      }
    },
    {
      "prediction": 0.7674605846405029,
      "confidence": -0.3571985744747253,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.01980358362197876,
        "delta": 0.3094708323478699,
        "magnitude_ratio": 0.03363115340471268
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 999
      }
    },
    {
      "prediction": 0.9223925471305847,
      "confidence": 0.31336579254705643,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.008058607578277588,
        "delta": 0.3233874440193176,
        "magnitude_ratio": 0.01653866097331047
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 765
      }
    },
    {
      "prediction": 0.9749385714530945,
      "confidence": 0.24782397599581837,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002829313278198242,
        "delta": 0.3388180732727051,
        "magnitude_ratio": 0.021161556243896484
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 939
      }
    },
    {
      "prediction": 0.21781189739704132,
      "confidence": 0.5666637077220295,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9924707412719727,
        "delta": 5.763185501098633,
        "magnitude_ratio": 0.016822896897792816
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 516
      }
    },
    {
      "prediction": 0.9576371312141418,
      "confidence": 0.11657006604669666,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002805471420288086,
        "delta": 0.24230892956256866,
        "magnitude_ratio": 0.005453711375594139
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 333
      }
    },
    {
      "prediction": 0.5512626767158508,
      "confidence": 0.2703881402781498,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004439890384674072,
        "delta": 0.24580532312393188,
        "magnitude_ratio": 0.011784961447119713
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 82
      }
    },
    {
      "prediction": 0.9464117884635925,
      "confidence": 0.4347017625174479,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0049367547035217285,
        "delta": 0.4426141381263733,
        "magnitude_ratio": 0.03820984065532684
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 865
      }
    },
    {
      "prediction": 0.879925549030304,
      "confidence": -0.13203697692523406,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006161093711853027,
        "delta": 0.19859547913074493,
        "magnitude_ratio": 0.004701162688434124
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 964
      }
    },
    {
      "prediction": 0.9878323078155518,
      "confidence": 0.36735677948667256,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002028942108154297,
        "delta": 0.21693800389766693,
        "magnitude_ratio": 0.005088762380182743
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 479
      }
    },
    {
      "prediction": 0.9739295244216919,
      "confidence": 0.3392157189617837,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.01168733835220337,
        "delta": 0.390207976102829,
        "magnitude_ratio": 0.0034259422682225704
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 306
      }
    },
    {
      "prediction": 0.5153504014015198,
      "confidence": 0.07190145955067546,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0037394165992736816,
        "delta": 0.2973949909210205,
        "magnitude_ratio": 0.007760487962514162
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 359
      }
    },
    {
      "prediction": 0.9404727816581726,
      "confidence": 0.10983048043970677,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003119051456451416,
        "delta": 0.2400752156972885,
        "magnitude_ratio": 0.009359623305499554
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 998
      }
    },
    {
      "prediction": 0.9833567142486572,
      "confidence": 0.1332346334382816,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004109203815460205,
        "delta": 0.3152061998844147,
        "magnitude_ratio": 0.02009008266031742
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 195
      }
    },
    {
      "prediction": 0.46325019001960754,
      "confidence": -0.16068693241865847,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002940654754638672,
        "delta": 0.16589266061782837,
        "magnitude_ratio": 0.008469200693070889
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 305
      }
    },
    {
      "prediction": 0.9291892647743225,
      "confidence": 0.3327155205837451,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0034859776496887207,
        "delta": 0.23335635662078857,
        "magnitude_ratio": 0.011190423741936684
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 139
      }
    },
    {
      "prediction": -0.010920600965619087,
      "confidence": 0.881346576297755,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.99757981300354,
        "delta": 4.784490585327148,
        "magnitude_ratio": 0.010482165962457657
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 587
      }
    },
    {
      "prediction": 0.3108651041984558,
      "confidence": 0.7219363306920759,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9954787492752075,
        "delta": 5.594401836395264,
        "magnitude_ratio": 0.00824671145528555
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 505
      }
    },
    {
      "prediction": 0.9829013347625732,
      "confidence": 0.28954524564575823,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0011963844299316406,
        "delta": 0.19931039214134216,
        "magnitude_ratio": 0.004564432427287102
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 298
      }
    },
    {
      "prediction": 0.9608322978019714,
      "confidence": 0.29168260499122195,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0043929219245910645,
        "delta": 0.2848362624645233,
        "magnitude_ratio": 0.0025322979781776667
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 340
      }
    },
    {
      "prediction": 0.17416895925998688,
      "confidence": 0.608276829228584,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9928200244903564,
        "delta": 5.112921237945557,
        "magnitude_ratio": 0.03221326693892479
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 191
      }
    },
    {
      "prediction": 0.14735178649425507,
      "confidence": 0.8435701518863178,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9978001117706299,
        "delta": 7.54114294052124,
        "magnitude_ratio": 0.01107182539999485
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 200
      }
    },
    {
      "prediction": 0.35629454255104065,
      "confidence": 0.7578746990912414,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9986845254898071,
        "delta": 6.786439418792725,
        "magnitude_ratio": 0.006449788808822632
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 899
      }
    },
    {
      "prediction": 0.7738947868347168,
      "confidence": -0.10755201619104611,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0046967267990112305,
        "delta": 0.1794562041759491,
        "magnitude_ratio": 0.014417066238820553
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 361
      }
    },
    {
      "prediction": 0.28789108991622925,
      "confidence": 0.6815928530773725,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9965410232543945,
        "delta": 5.9238715171813965,
        "magnitude_ratio": 0.01008243951946497
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 372
      }
    },
    {
      "prediction": 0.9231060147285461,
      "confidence": 0.04715414115881136,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.009666860103607178,
        "delta": 0.24198487401008606,
        "magnitude_ratio": 0.007841247133910656
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 668
      }
    },
    {
      "prediction": 0.973788321018219,
      "confidence": 0.21998265217673704,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0026375651359558105,
        "delta": 0.21776781976222992,
        "magnitude_ratio": 0.008111835457384586
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 272
      }
    },
    {
      "prediction": 0.4831298589706421,
      "confidence": 0.7292673441558654,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.98991060256958,
        "delta": 4.636385917663574,
        "magnitude_ratio": 0.009675201028585434
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 861
      }
    },
    {
      "prediction": 0.5201457738876343,
      "confidence": 0.19177631581558385,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004434168338775635,
        "delta": 0.257569283246994,
        "magnitude_ratio": 0.0023205834440886974
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 897
      }
    },
    {
      "prediction": 0.29893726110458374,
      "confidence": 0.690537752030016,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.993819236755371,
        "delta": 5.549659729003906,
        "magnitude_ratio": 0.0043335286900401115
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 182
      }
    },
    {
      "prediction": 0.9250045418739319,
      "confidence": 0.2271751956740837,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0026435256004333496,
        "delta": 0.22264645993709564,
        "magnitude_ratio": 0.009940475225448608
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 316
      }
    },
    {
      "prediction": 0.5476973056793213,
      "confidence": 0.2992264330022036,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.012204945087432861,
        "delta": 0.390337735414505,
        "magnitude_ratio": 0.013456903398036957
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 166
      }
    },
    {
      "prediction": 0.9328961968421936,
      "confidence": 0.0009550700912249651,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.010107636451721191,
        "delta": 0.406502902507782,
        "magnitude_ratio": 0.06368215382099152
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 0
      }
    },
    {
      "prediction": 0.28751057386398315,
      "confidence": 0.5954520438264758,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.994362235069275,
        "delta": 4.634130477905273,
        "magnitude_ratio": 0.04029891639947891
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 81
      }
    },
    {
      "prediction": 0.5134016275405884,
      "confidence": 0.6961712892727911,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9872344732284546,
        "delta": 5.808013439178467,
        "magnitude_ratio": 0.0172325000166893
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 966
      }
    },
    {
      "prediction": 0.10631490498781204,
      "confidence": 0.7235836775877155,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.994336724281311,
        "delta": 5.592155933380127,
        "magnitude_ratio": 0.004470020532608032
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 706
      }
    },
    {
      "prediction": 0.9718285202980042,
      "confidence": 0.3455538858183713,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0006658434867858887,
        "delta": 0.15523460507392883,
        "magnitude_ratio": 0.013106072321534157
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 304
      }
    },
    {
      "prediction": 0.94282066822052,
      "confidence": -0.01936505376786209,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.011295557022094727,
        "delta": 0.36559200286865234,
        "magnitude_ratio": 0.01068110391497612
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 194
      }
    },
    {
      "prediction": 0.8769809603691101,
      "confidence": 0.22643117431119697,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006257474422454834,
        "delta": 0.2916591167449951,
        "magnitude_ratio": 0.016299830749630928
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 946
      }
    },
    {
      "prediction": 0.9864988923072815,
      "confidence": 0.31469868377002275,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.000828862190246582,
        "delta": 0.14249081909656525,
        "magnitude_ratio": 0.008047704584896564
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 717
      }
    },
    {
      "prediction": 0.8026270270347595,
      "confidence": -0.03156860944188495,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0036816000938415527,
        "delta": 0.2464727759361267,
        "magnitude_ratio": 0.01023799180984497
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 52
      }
    },
    {
      "prediction": 0.9533326625823975,
      "confidence": 0.06383920359852936,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005697309970855713,
        "delta": 0.2791862189769745,
        "magnitude_ratio": 0.004099763464182615
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 531
      }
    },
    {
      "prediction": 0.9798305034637451,
      "confidence": -0.009845081096887512,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0014264583587646484,
        "delta": 0.21529929339885712,
        "magnitude_ratio": 0.02582714706659317
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 31
      }
    },
    {
      "prediction": 0.9779655933380127,
      "confidence": 0.3357760593769968,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003168940544128418,
        "delta": 0.29102659225463867,
        "magnitude_ratio": 0.01749962754547596
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 398
      }
    },
    {
      "prediction": 0.6614042520523071,
      "confidence": 0.22664296669211845,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.00895625352859497,
        "delta": 0.37149685621261597,
        "magnitude_ratio": 0.003242660081014037
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 757
      }
    },
    {
      "prediction": 0.8186222910881042,
      "confidence": 0.11046183496967661,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005454659461975098,
        "delta": 0.23904159665107727,
        "magnitude_ratio": 0.0170038640499115
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 730
      }
    },
    {
      "prediction": 0.9176250696182251,
      "confidence": 0.276541522150133,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006374835968017578,
        "delta": 0.3370869755744934,
        "magnitude_ratio": 0.0027915167156606913
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 807
      }
    },
    {
      "prediction": 0.35581323504447937,
      "confidence": 0.7326807693345687,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9963711500167847,
        "delta": 6.70042085647583,
        "magnitude_ratio": 0.0002397298812866211
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 114
      }
    },
    {
      "prediction": 0.8621916174888611,
      "confidence": -0.3846665729385221,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006757616996765137,
        "delta": 0.27226313948631287,
        "magnitude_ratio": 0.03840083256363869
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 833
      }
    },
    {
      "prediction": 0.12869416177272797,
      "confidence": 0.7785510103291653,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9975554943084717,
        "delta": 5.410116672515869,
        "magnitude_ratio": 0.04939603805541992
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 748
      }
    },
    {
      "prediction": 0.9391586780548096,
      "confidence": 0.19063027317835324,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005427300930023193,
        "delta": 0.29353201389312744,
        "magnitude_ratio": 0.032058753073215485
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 605
      }
    },
    {
      "prediction": 0.48996633291244507,
      "confidence": -0.25257634467198253,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.01497739553451538,
        "delta": 0.3597980737686157,
        "magnitude_ratio": 0.00519491545855999
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 152
      }
    },
    {
      "prediction": 0.551478922367096,
      "confidence": 0.43916048932219254,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004067838191986084,
        "delta": 0.3501802682876587,
        "magnitude_ratio": 0.023929854854941368
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 237
      }
    },
    {
      "prediction": 0.48712071776390076,
      "confidence": 0.047505063011214016,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.007140159606933594,
        "delta": 0.28529730439186096,
        "magnitude_ratio": 0.032051607966423035
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 334
      }
    },
    {
      "prediction": 0.94693922996521,
      "confidence": 0.07461967908067298,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0021703243255615234,
        "delta": 0.21663616597652435,
        "magnitude_ratio": 0.0015361893456429243
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 28
      }
    },
    {
      "prediction": 0.513355016708374,
      "confidence": 0.27416665977773763,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.012563824653625488,
        "delta": 0.38510772585868835,
        "magnitude_ratio": 0.016689300537109375
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 439
      }
    },
    {
      "prediction": 0.932518720626831,
      "confidence": 0.28189149079828707,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.001982450485229492,
        "delta": 0.223516047000885,
        "magnitude_ratio": 0.00447353720664978
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 417
      }
    },
    {
      "prediction": 0.9501470327377319,
      "confidence": 0.029761330118897908,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0013661980628967285,
        "delta": 0.15789178013801575,
        "magnitude_ratio": 0.003531798953190446
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 586
      }
    },
    {
      "prediction": 0.49930816888809204,
      "confidence": -0.36964641024962286,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.011600136756896973,
        "delta": 0.3005198836326599,
        "magnitude_ratio": 0.06185077130794525
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 269
      }
    },
    {
      "prediction": 0.454826295375824,
      "confidence": -0.37202355986372715,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.002701997756958008,
        "delta": 0.1299985945224762,
        "magnitude_ratio": 0.007188673131167889
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 836
      }
    },
    {
      "prediction": 0.4550079107284546,
      "confidence": 0.650419633117623,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9957877397537231,
        "delta": 5.46604585647583,
        "magnitude_ratio": 0.008726494386792183
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 576
      }
    },
    {
      "prediction": 0.929212212562561,
      "confidence": 0.24072865357410075,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.006340384483337402,
        "delta": 0.27573660016059875,
        "magnitude_ratio": 0.01215487439185381
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 157
      }
    },
    {
      "prediction": 0.8897281289100647,
      "confidence": 0.3822007477906281,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003014087677001953,
        "delta": 0.35272565484046936,
        "magnitude_ratio": 0.03897658362984657
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 452
      }
    },
    {
      "prediction": 0.9596952795982361,
      "confidence": 0.23342670246920652,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003065347671508789,
        "delta": 0.19982729852199554,
        "magnitude_ratio": 0.0012691013980656862
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 332
      }
    },
    {
      "prediction": 0.9515882134437561,
      "confidence": -0.2153914360324789,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0066918134689331055,
        "delta": 0.35933932662010193,
        "magnitude_ratio": 0.0090745585039258
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 893
      }
    },
    {
      "prediction": 0.9460328817367554,
      "confidence": 0.39020563380680034,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004150271415710449,
        "delta": 0.30364102125167847,
        "magnitude_ratio": 0.0076814573258161545
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 344
      }
    },
    {
      "prediction": 0.8243720531463623,
      "confidence": 0.15876810384561704,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.01604551076889038,
        "delta": 0.39959779381752014,
        "magnitude_ratio": 0.032350216060876846
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 486
      }
    },
    {
      "prediction": 0.5103176832199097,
      "confidence": 0.7121298474703615,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9971833229064941,
        "delta": 5.619130611419678,
        "magnitude_ratio": 0.029034260660409927
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 655
      }
    },
    {
      "prediction": 0.9932101368904114,
      "confidence": 0.27736270833173265,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003436446189880371,
        "delta": 0.3339891731739044,
        "magnitude_ratio": 0.0010380741441622376
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 249
      }
    },
    {
      "prediction": 0.8877419233322144,
      "confidence": 0.14069974718245656,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004913985729217529,
        "delta": 0.32489410042762756,
        "magnitude_ratio": 0.0112838726490736
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 411
      }
    },
    {
      "prediction": 0.918502151966095,
      "confidence": 0.003069884943216398,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.004369795322418213,
        "delta": 0.29054635763168335,
        "magnitude_ratio": 0.02518055960536003
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 815
      }
    },
    {
      "prediction": -0.032960254698991776,
      "confidence": 0.8304790144962834,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.997268557548523,
        "delta": 5.163908958435059,
        "magnitude_ratio": 0.044488608837127686
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 701
      }
    },
    {
      "prediction": 0.5220960378646851,
      "confidence": 0.710131722979221,
      "expert_used": "AntiBExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 1.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9949696063995361,
        "delta": 5.067837238311768,
        "magnitude_ratio": 0.003348755184561014
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 3
      }
    },
    {
      "prediction": 0.9118419885635376,
      "confidence": 0.266329407136805,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003785252571105957,
        "delta": 0.2913973033428192,
        "magnitude_ratio": 0.026280667632818222
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 554
      }
    },
    {
      "prediction": 0.967609703540802,
      "confidence": 0.23876406042420292,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.003072381019592285,
        "delta": 0.2630085051059723,
        "magnitude_ratio": 0.001170217408798635
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 230
      }
    },
    {
      "prediction": 0.531489372253418,
      "confidence": -0.15610774615769002,
      "expert_used": "AntiAExpert",
      "gate_scores": {
        "AlignedExpert": 0.0,
        "AntiAExpert": 1.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.011285364627838135,
        "delta": 0.30227312445640564,
        "magnitude_ratio": 0.014096756465733051
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 122
      }
    },
    {
      "prediction": 0.9116248488426208,
      "confidence": 0.18764052072997506,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0034456849098205566,
        "delta": 0.2553975582122803,
        "magnitude_ratio": 0.003293800400570035
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 175
      }
    },
    {
      "prediction": 0.2417539358139038,
      "confidence": 0.8820883545269173,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.99666166305542,
        "delta": 5.712698936462402,
        "magnitude_ratio": 0.013739317655563354
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 286
      }
    },
    {
      "prediction": 0.7067111134529114,
      "confidence": -0.42827358524158193,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.020710110664367676,
        "delta": 0.31629377603530884,
        "magnitude_ratio": 0.028206374496221542
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 370
      }
    },
    {
      "prediction": 0.9405019283294678,
      "confidence": 0.20913674732076873,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005246341228485107,
        "delta": 0.3099590241909027,
        "magnitude_ratio": 0.022143080830574036
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 911
      }
    },
    {
      "prediction": 0.9210071563720703,
      "confidence": 0.16047738582659812,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0070053935050964355,
        "delta": 0.2585093677043915,
        "magnitude_ratio": 0.02322142943739891
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 509
      }
    },
    {
      "prediction": 0.9795337915420532,
      "confidence": 0.25366996577190004,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0019437670707702637,
        "delta": 0.2816183269023895,
        "magnitude_ratio": 0.01057054940611124
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 65
      }
    },
    {
      "prediction": 0.8974350690841675,
      "confidence": -0.0064183977158850615,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.009167313575744629,
        "delta": 0.26847198605537415,
        "magnitude_ratio": 0.004318925552070141
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 629
      }
    },
    {
      "prediction": 0.4103577733039856,
      "confidence": 0.8337785631572955,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9961458444595337,
        "delta": 6.312047481536865,
        "magnitude_ratio": 0.0032678726129233837
      },
      "abstained": "True",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 970
      }
    },
    {
      "prediction": 0.9105709195137024,
      "confidence": 0.26639304136120506,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.014279842376708984,
        "delta": 0.4067424535751343,
        "magnitude_ratio": 0.012254399247467518
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 508
      }
    },
    {
      "prediction": 0.8234423995018005,
      "confidence": 0.14939011777761033,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.000843346118927002,
        "delta": 0.12898066639900208,
        "magnitude_ratio": 0.016047649085521698
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 515
      }
    },
    {
      "prediction": 0.06119848042726517,
      "confidence": 0.6068929784200425,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9936878681182861,
        "delta": 5.590082168579102,
        "magnitude_ratio": 0.00038009879062883556
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 30
      }
    },
    {
      "prediction": 0.9942423105239868,
      "confidence": 0.33733765929698967,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0028631091117858887,
        "delta": 0.3143215477466583,
        "magnitude_ratio": 0.017702994868159294
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 493
      }
    },
    {
      "prediction": 0.4926501512527466,
      "confidence": 0.7287586334403556,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9975864887237549,
        "delta": 7.321776866912842,
        "magnitude_ratio": 0.0363125205039978
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 78
      }
    },
    {
      "prediction": 0.19979062676429749,
      "confidence": 0.3991876206984819,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.999050498008728,
        "delta": 5.9566874504089355,
        "magnitude_ratio": 0.000521838606800884
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 534
      }
    },
    {
      "prediction": 0.9131311178207397,
      "confidence": 0.05872508563172132,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0037154555320739746,
        "delta": 0.28806477785110474,
        "magnitude_ratio": 0.04326305538415909
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 744
      }
    },
    {
      "prediction": 0.9754589200019836,
      "confidence": 0.019959344597289163,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0026965737342834473,
        "delta": 0.24062693119049072,
        "magnitude_ratio": 0.016317766159772873
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 140
      }
    },
    {
      "prediction": 0.34200534224510193,
      "confidence": 0.7297314176926012,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9970567226409912,
        "delta": 5.438972473144531,
        "magnitude_ratio": 0.03700139746069908
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 941
      }
    },
    {
      "prediction": 0.37280306220054626,
      "confidence": 0.7103308269138152,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9953501224517822,
        "delta": 7.327874183654785,
        "magnitude_ratio": 0.0038235001266002655
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 828
      }
    },
    {
      "prediction": 0.9336587190628052,
      "confidence": 0.23860829069989656,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005930423736572266,
        "delta": 0.3342881202697754,
        "magnitude_ratio": 0.0024414609652012587
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 110
      }
    },
    {
      "prediction": 0.9413413405418396,
      "confidence": 0.3868396187841945,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.0038001537322998047,
        "delta": 0.28540027141571045,
        "magnitude_ratio": 0.0114881107583642
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 787
      }
    },
    {
      "prediction": 0.2998068928718567,
      "confidence": 0.34264024629671,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 1.9915341138839722,
        "delta": 4.544058322906494,
        "magnitude_ratio": 0.01124447863548994
      },
      "abstained": "False",
      "true_label": 0.0,
      "regime": "contradictory",
      "metadata": {
        "has_contradiction": true,
        "generated_at": 261
      }
    },
    {
      "prediction": 0.9555997252464294,
      "confidence": 0.4808805491605839,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.005937635898590088,
        "delta": 0.3461425304412842,
        "magnitude_ratio": 0.014877294190227985
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 60
      }
    },
    {
      "prediction": 0.6716328263282776,
      "confidence": 0.16089206766094666,
      "expert_used": "AlignedExpert",
      "gate_scores": {
        "AlignedExpert": 1.0,
        "AntiAExpert": 0.0,
        "AntiBExpert": 0.0,
        "SafeFallbackExpert": 0.0
      },
      "contradiction_scores": {
        "cosine": 0.03130894899368286,
        "delta": 0.5051657557487488,
        "magnitude_ratio": 0.045968297868967056
      },
      "abstained": "False",
      "true_label": 1.0,
      "regime": "aligned",
      "metadata": {
        "has_contradiction": false,
        "generated_at": 473
      }
    }
  ],
  "timestamp": "2025-08-18T22:29:28.129777"
}